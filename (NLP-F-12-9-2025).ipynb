{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnVRW/DPpoEWD9yWLZk7eW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaishnaviBairagoni/Natural-Language-Processing-NLP-/blob/main/(NLP-F-12-9-2025).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep Learning\n",
        "#Preprocessing\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/tweets.csv\")  # adjust path if needed\n",
        "\n",
        "# Define stopwords\n",
        "stopwords = set(ENGLISH_STOP_WORDS)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(s):\n",
        "    s = str(s).lower()                      # lowercase\n",
        "    s = re.sub(r'http\\S+|www\\.\\S+', ' ', s)  # remove URLs\n",
        "    s = re.sub(r'@\\w+', ' ', s)               # remove mentions\n",
        "    s = re.sub(r'#\\w+', ' ', s)               # remove hashtags\n",
        "    s = re.sub(r'[^a-z\\s]', ' ', s)           # remove punctuation, numbers, special chars\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()        # remove extra spaces\n",
        "    tokens = [w for w in s.split() if w not in stopwords and len(w) > 1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"clean\"] = df[\"text\"].astype(str).apply(preprocess_text)\n",
        "\n",
        "print(df[[\"text\", \"clean\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH-oBlJBMGPO",
        "outputId": "2f8ef18f-cf8d-41be-db02-9986c0e24766"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  Communal violence in Bhainsa, Telangana. \"Ston...   \n",
            "1  Telangana: Section 144 has been imposed in Bha...   \n",
            "2  Arsonist sets cars ablaze at dealership https:...   \n",
            "3  Arsonist sets cars ablaze at dealership https:...   \n",
            "4  \"Lord Jesus, your love brings freedom and pard...   \n",
            "\n",
            "                                               clean  \n",
            "0  communal violence bhainsa telangana stones pel...  \n",
            "1  telangana section imposed bhainsa january clas...  \n",
            "2               arsonist sets cars ablaze dealership  \n",
            "3               arsonist sets cars ablaze dealership  \n",
            "4  lord jesus love brings freedom pardon holy spi...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction: CountVectorizer (bag-of-words) + TF-IDF\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    df['clean'].values, df['target'].values, test_size=0.2, stratify=df['target'].values, random_state=42\n",
        ")\n",
        "\n",
        "# --- CountVectorizer (countervctor) ---\n",
        "count_vect = CountVectorizer(\n",
        "    max_features=10000,      # adjust up/down based on memory\n",
        "    ngram_range=(1,2),       # unigrams + bigrams often helpful for tweets\n",
        "    min_df=2,                # ignore extremely rare tokens\n",
        "    binary=False\n",
        ")\n",
        "X_train_count = count_vect.fit_transform(X_train_raw)\n",
        "X_test_count  = count_vect.transform(X_test_raw)\n",
        "\n",
        "print(\"Count vector shape:\", X_train_count.shape)  # (n_samples, vocab_size)\n",
        "\n",
        "# Save for later reuse\n",
        "joblib.dump(count_vect, \"count_vectorizer.joblib\")\n",
        "\n",
        "# --- TF-IDF Vectorizer ---\n",
        "tfidf_vect = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    norm='l2',\n",
        "    sublinear_tf=True\n",
        ")\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train_raw)\n",
        "X_test_tfidf  = tfidf_vect.transform(X_test_raw)\n",
        "\n",
        "print(\"TF-IDF shape:\", X_train_tfidf.shape)\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "joblib.dump(tfidf_vect, \"tfidf_vectorizer.joblib\")\n",
        "\n",
        "# Optional quick sanity: top features\n",
        "def top_terms(vectorizer, k=20):\n",
        "    feat = vectorizer.get_feature_names_out()\n",
        "    return feat[:k]\n",
        "\n",
        "print(\"Sample TF-IDF features:\", top_terms(tfidf_vect, 20))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vq4QQVSN9vX",
        "outputId": "6ff9ed3f-96e2-44b2-c9fb-1809651e6d26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count vector shape: (9096, 10000)\n",
            "TF-IDF shape: (9096, 10000)\n",
            "Sample TF-IDF features: ['ab' 'abandoned' 'abbott' 'abby' 'abc' 'ablaze' 'ablaze dealership'\n",
            " 'able' 'able totally' 'able touch' 'abnormal' 'abo' 'aboard'\n",
            " 'abomination' 'abomination desolation' 'aboriginal' 'aboriginal planners'\n",
            " 'abortion' 'abortion true' 'abou']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning Models (Keras)\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (Input, Embedding, GlobalAveragePooling1D, Dense, Dropout,\n",
        "                                     Conv1D, GlobalMaxPooling1D, SpatialDropout1D,\n",
        "                                     LSTM, Bidirectional)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "#Hyperparams\n",
        "MAX_NUM_WORDS = 20000\n",
        "MAX_SEQUENCE_LENGTH = 60\n",
        "EMBEDDING_DIM = 100\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 6\n",
        "\n",
        "# Optional: use pretrained GloVe if you have it (download glove.6B.100d.txt to working dir)\n",
        "USE_GLOVE = False\n",
        "GLOVE_PATH = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Tokenize + Pad\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_raw)         # X_train_raw should be an array/list of cleaned strings\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_raw)\n",
        "X_test_seq  = tokenizer.texts_to_sequences(X_test_raw)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "X_test_pad  = pad_sequences(X_test_seq,  maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "vocab_size = min(MAX_NUM_WORDS, len(tokenizer.word_index) + 1)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "# Optional: build embedding matrix from GloVe\n",
        "embedding_matrix = None\n",
        "if USE_GLOVE:\n",
        "    if not os.path.exists(GLOVE_PATH):\n",
        "        raise FileNotFoundError(f\"GloVe file not found at {GLOVE_PATH}. Set USE_GLOVE=False or provide the file.\")\n",
        "    print(\"Loading GloVe vectors (this may take a minute)...\")\n",
        "    embeddings_index = {}\n",
        "    with open(GLOVE_PATH, \"r\", encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.rstrip().split(\" \")\n",
        "            word = parts[0]\n",
        "            vec = np.asarray(parts[1:], dtype=\"float32\")\n",
        "            embeddings_index[word] = vec\n",
        "    embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    for word, idx in tokenizer.word_index.items():\n",
        "        if idx >= vocab_size:\n",
        "            continue\n",
        "        vec = embeddings_index.get(word)\n",
        "        if vec is not None and vec.shape[0] == EMBEDDING_DIM:\n",
        "            embedding_matrix[idx] = vec\n",
        "    print(\"Prepared embedding matrix.\")\n",
        "\n",
        "# ---------------- Utility: evaluation ----------------\n",
        "results = []\n",
        "\n",
        "def eval_and_store(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    print(f\"\\n{name} | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
        "    print(classification_report(y_true, y_pred, digits=4))\n",
        "    results.append({\"model\": name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1})\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True, verbose=1)\n",
        "\n",
        "#  Model 1: MLP on averaged embeddings\n",
        "print(\"\\nBuilding and training: MLP (avg embeddings)\")\n",
        "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
        "if USE_GLOVE and (embedding_matrix is not None):\n",
        "    emb = Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)(inputs)\n",
        "else:\n",
        "    emb = Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(inputs)\n",
        "\n",
        "x = GlobalAveragePooling1D()(emb)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "mlp_model = Model(inputs, outputs)\n",
        "mlp_model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "mlp_model.summary()\n",
        "mlp_model.fit(X_train_pad, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
        "\n",
        "y_pred_mlp = (mlp_model.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "eval_and_store(\"MLP (avg embeddings)\", y_test, y_pred_mlp)\n",
        "\n",
        "#  Model 2: 1D-CNN\n",
        "print(\"\\nBuilding and training: 1D-CNN\")\n",
        "cnn = Sequential()\n",
        "if USE_GLOVE and (embedding_matrix is not None):\n",
        "    cnn.add(Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "else:\n",
        "    cnn.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "cnn.add(Conv1D(128, kernel_size=5, activation=\"relu\"))\n",
        "cnn.add(GlobalMaxPooling1D())\n",
        "cnn.add(Dense(64, activation=\"relu\"))\n",
        "cnn.add(Dropout(0.3))\n",
        "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "cnn.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "cnn.summary()\n",
        "cnn.fit(X_train_pad, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
        "\n",
        "y_pred_cnn = (cnn.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "eval_and_store(\"1D-CNN\", y_test, y_pred_cnn)\n",
        "\n",
        "# Model 3: Bidirectional LSTM\n",
        "print(\"\\nBuilding and training: Bidirectional LSTM\")\n",
        "lstm_model = Sequential()\n",
        "if USE_GLOVE and (embedding_matrix is not None):\n",
        "    lstm_model.add(Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "else:\n",
        "    lstm_model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "lstm_model.add(SpatialDropout1D(0.2))\n",
        "lstm_model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
        "lstm_model.add(Dense(64, activation=\"relu\"))\n",
        "lstm_model.add(Dropout(0.3))\n",
        "lstm_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "lstm_model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "lstm_model.summary()\n",
        "lstm_model.fit(X_train_pad, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
        "\n",
        "y_pred_lstm = (lstm_model.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "eval_and_store(\"Bidirectional LSTM\", y_test, y_pred_lstm)\n",
        "\n",
        "#Save models and tokenizer\n",
        "mlp_model.save(\"mlp_avg_embeddings.h5\")\n",
        "cnn.save(\"cnn_text.h5\")\n",
        "lstm_model.save(\"bilstm_text.h5\")\n",
        "joblib.dump(tokenizer, \"tokenizer.joblib\")\n",
        "\n",
        "# Save results dataframe\n",
        "import pandas as pd\n",
        "res_df = pd.DataFrame(results).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
        "res_df.to_csv(\"dl_experiment_results.csv\", index=False)\n",
        "print(\"\\nSaved dl_experiment_results.csv and model files (h5) and tokenizer.joblib\")\n",
        "\n",
        "# Done.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "soRjC4JARh4W",
        "outputId": "213cfe24-4e4e-4f62-f8bc-49f299d821d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 17101\n",
            "\n",
            "Building and training: MLP (avg embeddings)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,710,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,710,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,716,629\u001b[0m (6.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,716,629</span> (6.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,716,629\u001b[0m (6.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,716,629</span> (6.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7644 - loss: 0.5232 - val_accuracy: 0.7912 - val_loss: 0.5077\n",
            "Epoch 2/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.4828 - val_accuracy: 0.7912 - val_loss: 0.5066\n",
            "Epoch 3/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.4767 - val_accuracy: 0.7912 - val_loss: 0.5031\n",
            "Epoch 4/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.4741 - val_accuracy: 0.7912 - val_loss: 0.4963\n",
            "Epoch 5/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.4651 - val_accuracy: 0.7912 - val_loss: 0.4819\n",
            "Epoch 6/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.4444 - val_accuracy: 0.7912 - val_loss: 0.4491\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "MLP (avg embeddings) | Acc: 0.8140 | Prec: 0.0000 | Rec: 0.0000 | F1: 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8140    1.0000    0.8975      1851\n",
            "           1     0.0000    0.0000    0.0000       423\n",
            "\n",
            "    accuracy                         0.8140      2274\n",
            "   macro avg     0.4070    0.5000    0.4487      2274\n",
            "weighted avg     0.6626    0.8140    0.7305      2274\n",
            "\n",
            "\n",
            "Building and training: 1D-CNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8119 - loss: 0.5253 - val_accuracy: 0.7912 - val_loss: 0.4629\n",
            "Epoch 2/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.8383 - loss: 0.3480 - val_accuracy: 0.8890 - val_loss: 0.3251\n",
            "Epoch 3/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.9564 - loss: 0.1353 - val_accuracy: 0.8747 - val_loss: 0.4003\n",
            "Epoch 4/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.9863 - loss: 0.0526 - val_accuracy: 0.8824 - val_loss: 0.5309\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "1D-CNN | Acc: 0.8676 | Prec: 0.6667 | Rec: 0.5768 | F1: 0.6185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9062    0.9341    0.9199      1851\n",
            "           1     0.6667    0.5768    0.6185       423\n",
            "\n",
            "    accuracy                         0.8676      2274\n",
            "   macro avg     0.7864    0.7555    0.7692      2274\n",
            "weighted avg     0.8616    0.8676    0.8639      2274\n",
            "\n",
            "\n",
            "Building and training: Bidirectional LSTM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 325ms/step - accuracy: 0.7710 - loss: 0.5374 - val_accuracy: 0.7912 - val_loss: 0.4576\n",
            "Epoch 2/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 323ms/step - accuracy: 0.8518 - loss: 0.3555 - val_accuracy: 0.8868 - val_loss: 0.3193\n",
            "Epoch 3/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 298ms/step - accuracy: 0.9406 - loss: 0.1583 - val_accuracy: 0.8824 - val_loss: 0.3601\n",
            "Epoch 4/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 345ms/step - accuracy: 0.9706 - loss: 0.0907 - val_accuracy: 0.8703 - val_loss: 0.4392\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bidirectional LSTM | Acc: 0.8826 | Prec: 0.7532 | Rec: 0.5485 | F1: 0.6347\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9028    0.9589    0.9300      1851\n",
            "           1     0.7532    0.5485    0.6347       423\n",
            "\n",
            "    accuracy                         0.8826      2274\n",
            "   macro avg     0.8280    0.7537    0.7824      2274\n",
            "weighted avg     0.8750    0.8826    0.8751      2274\n",
            "\n",
            "\n",
            "Saved dl_experiment_results.csv and model files (h5) and tokenizer.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Section\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "results = []\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    \"\"\"Compute and print evaluation metrics, store in results list.\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall   : {rec:.4f}\")\n",
        "    print(f\"F1-score : {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "\n",
        "# Logistic Regression (TF-IDF)\n",
        "if 'lr' in globals():\n",
        "    y_pred_lr = lr.predict(X_test_tfidf)\n",
        "    evaluate_model(\"Logistic Regression (TF-IDF)\", y_test, y_pred_lr)\n",
        "\n",
        "# SVM (TF-IDF)\n",
        "if 'svc' in globals():\n",
        "    y_pred_svc = svc.predict(X_test_tfidf)\n",
        "    evaluate_model(\"SVM (TF-IDF)\", y_test, y_pred_svc)\n",
        "\n",
        "# MLP (avg embeddings)\n",
        "if 'mlp_model' in globals():\n",
        "    y_pred_mlp = (mlp_model.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "    evaluate_model(\"MLP (avg embeddings)\", y_test, y_pred_mlp)\n",
        "\n",
        "# 1D-CNN\n",
        "if 'cnn' in globals():\n",
        "    y_pred_cnn = (cnn.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "    evaluate_model(\"1D-CNN\", y_test, y_pred_cnn)\n",
        "\n",
        "# LSTM\n",
        "if 'lstm_model' in globals():\n",
        "    y_pred_lstm = (lstm_model.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "    evaluate_model(\"Bidirectional LSTM\", y_test, y_pred_lstm)\n",
        "\n",
        "# Save Summary\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"evaluation_summary.csv\", index=False)\n",
        "print(\"\\nSaved evaluation_summary.csv with all metrics.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaacEdvHS868",
        "outputId": "64cc0e66-a17d-4a21-8306-126f27551579"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP (avg embeddings)\n",
            "Accuracy : 0.8140\n",
            "Precision: 0.0000\n",
            "Recall   : 0.0000\n",
            "F1-score : 0.0000\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8140    1.0000    0.8975      1851\n",
            "           1     0.0000    0.0000    0.0000       423\n",
            "\n",
            "    accuracy                         0.8140      2274\n",
            "   macro avg     0.4070    0.5000    0.4487      2274\n",
            "weighted avg     0.6626    0.8140    0.7305      2274\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1D-CNN\n",
            "Accuracy : 0.8676\n",
            "Precision: 0.6667\n",
            "Recall   : 0.5768\n",
            "F1-score : 0.6185\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9062    0.9341    0.9199      1851\n",
            "           1     0.6667    0.5768    0.6185       423\n",
            "\n",
            "    accuracy                         0.8676      2274\n",
            "   macro avg     0.7864    0.7555    0.7692      2274\n",
            "weighted avg     0.8616    0.8676    0.8639      2274\n",
            "\n",
            "\n",
            "Bidirectional LSTM\n",
            "Accuracy : 0.8826\n",
            "Precision: 0.7532\n",
            "Recall   : 0.5485\n",
            "F1-score : 0.6347\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9028    0.9589    0.9300      1851\n",
            "           1     0.7532    0.5485    0.6347       423\n",
            "\n",
            "    accuracy                         0.8826      2274\n",
            "   macro avg     0.8280    0.7537    0.7824      2274\n",
            "weighted avg     0.8750    0.8826    0.8751      2274\n",
            "\n",
            "\n",
            "Saved evaluation_summary.csv with all metrics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Brief Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load results_df if not present in memory\n",
        "if 'results_df' not in globals():\n",
        "    if os.path.exists(\"evaluation_summary.csv\"):\n",
        "        results_df = pd.read_csv(\"evaluation_summary.csv\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"evaluation_summary.csv not found and results_df not in globals(). Run evaluation first.\")\n",
        "\n",
        "# Ensure consistent column names\n",
        "expected_cols = {'model', 'accuracy', 'precision', 'recall', 'f1'}\n",
        "if not expected_cols.issubset(set(results_df.columns)):\n",
        "    raise ValueError(f\"evaluation_summary.csv must contain columns: {expected_cols}\")\n",
        "\n",
        "# Normalize model name strings for grouping\n",
        "def normalize(name):\n",
        "    return name.strip().lower()\n",
        "\n",
        "results_df['model_norm'] = results_df['model'].apply(normalize)\n",
        "\n",
        "# Define groups\n",
        "tfidf_models = results_df[results_df['model_norm'].str.contains('tf-idf') | results_df['model_norm'].str.contains('tfidf') | results_df['model_norm'].str.contains('logistic') | results_df['model_norm'].str.contains('svm')]\n",
        "dl_models = results_df[results_df['model_norm'].str.contains('mlp') | results_df['model_norm'].str.contains('cnn') | results_df['model_norm'].str.contains('lstm') | results_df['model_norm'].str.contains('bilstm')]\n",
        "\n",
        "# Safety checks\n",
        "if tfidf_models.empty:\n",
        "    print(\"Warning: no TF-IDF classical models found in results to compare.\")\n",
        "if dl_models.empty:\n",
        "    print(\"Warning: no deep-learning (embedding) models found in results to compare.\")\n",
        "\n",
        "# Aggregate metrics\n",
        "def safe_mean(df, col):\n",
        "    return float(df[col].mean()) if not df.empty else float('nan')\n",
        "\n",
        "summary = {\n",
        "    'tfidf_count': len(tfidf_models),\n",
        "    'dl_count': len(dl_models),\n",
        "    'tfidf_mean_f1': safe_mean(tfidf_models, 'f1'),\n",
        "    'dl_mean_f1': safe_mean(dl_models, 'f1'),\n",
        "    'tfidf_mean_precision': safe_mean(tfidf_models, 'precision'),\n",
        "    'dl_mean_precision': safe_mean(dl_models, 'precision'),\n",
        "    'tfidf_mean_recall': safe_mean(tfidf_models, 'recall'),\n",
        "    'dl_mean_recall': safe_mean(dl_models, 'recall'),\n",
        "}\n",
        "\n",
        "# Which DL architecture benefited most? pick best by F1\n",
        "best_dl = None\n",
        "if not dl_models.empty:\n",
        "    best_dl_row = dl_models.loc[dl_models['f1'].idxmax()]\n",
        "    best_dl = {\n",
        "        'model': best_dl_row['model'],\n",
        "        'f1': float(best_dl_row['f1']),\n",
        "        'precision': float(best_dl_row['precision']),\n",
        "        'recall': float(best_dl_row['recall'])\n",
        "    }\n",
        "\n",
        "# Compare best DL vs best TF-IDF\n",
        "best_tfidf = None\n",
        "if not tfidf_models.empty:\n",
        "    best_tfidf_row = tfidf_models.loc[tfidf_models['f1'].idxmax()]\n",
        "    best_tfidf = {\n",
        "        'model': best_tfidf_row['model'],\n",
        "        'f1': float(best_tfidf_row['f1']),\n",
        "        'precision': float(best_tfidf_row['precision']),\n",
        "        'recall': float(best_tfidf_row['recall'])\n",
        "    }\n",
        "\n",
        "# Did embeddings improve performance over TF-IDF? (simple comparison)\n",
        "embeddings_improved = None\n",
        "f1_diff = None\n",
        "if not np.isnan(summary['tfidf_mean_f1']) and not np.isnan(summary['dl_mean_f1']):\n",
        "    f1_diff = summary['dl_mean_f1'] - summary['tfidf_mean_f1']\n",
        "    embeddings_improved = f1_diff > 0\n",
        "\n",
        "# Are sequential models (LSTM) better than CNN/MLP?\n",
        "lstm_row = dl_models[dl_models['model_norm'].str.contains('lstm')]\n",
        "cnn_row = dl_models[dl_models['model_norm'].str.contains('cnn')]\n",
        "mlp_row = dl_models[dl_models['model_norm'].str.contains('mlp')]\n",
        "\n",
        "lstm_best = None\n",
        "if not lstm_row.empty:\n",
        "    lstm_best = lstm_row.loc[lstm_row['f1'].idxmax()].to_dict()\n",
        "cnn_best = None\n",
        "if not cnn_row.empty:\n",
        "    cnn_best = cnn_row.loc[cnn_row['f1'].idxmax()].to_dict()\n",
        "mlp_best = None\n",
        "if not mlp_row.empty:\n",
        "    mlp_best = mlp_row.loc[mlp_row['f1'].idxmax()].to_dict()\n",
        "\n",
        "# Compose textual brief\n",
        "lines = []\n",
        "lines.append(\"BRIEF ANALYSIS - Disaster Tweets Experiment\")\n",
        "lines.append(\"==========================================\")\n",
        "lines.append(f\"TF-IDF models found: {summary['tfidf_count']}, DL models found: {summary['dl_count']}\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"Mean metrics:\")\n",
        "lines.append(f\"  - TF-IDF mean F1 : {summary['tfidf_mean_f1']:.4f}\" if not np.isnan(summary['tfidf_mean_f1']) else \"  - TF-IDF mean F1 : N/A\")\n",
        "lines.append(f\"  - DL mean F1     : {summary['dl_mean_f1']:.4f}\" if not np.isnan(summary['dl_mean_f1']) else \"  - DL mean F1     : N/A\")\n",
        "lines.append(\"\")\n",
        "if f1_diff is not None:\n",
        "    lines.append(f\"Overall difference (DL_mean_F1 - TFIDF_mean_F1) = {f1_diff:.4f}\")\n",
        "    lines.append(f\"Conclusion: Embeddings {'improved' if embeddings_improved else 'did NOT improve'} performance compared to TF-IDF (by mean F1).\")\n",
        "else:\n",
        "    lines.append(\"Not enough data to compare TF-IDF and DL mean F1.\")\n",
        "\n",
        "lines.append(\"\")\n",
        "if best_dl is not None:\n",
        "    lines.append(f\"Best DL model by F1: {best_dl['model']}  (F1={best_dl['f1']:.4f}, Precision={best_dl['precision']:.4f}, Recall={best_dl['recall']:.4f})\")\n",
        "else:\n",
        "    lines.append(\"No DL models available to pick best.\")\n",
        "\n",
        "if best_tfidf is not None:\n",
        "    lines.append(f\"Best TF-IDF model by F1: {best_tfidf['model']}  (F1={best_tfidf['f1']:.4f}, Precision={best_tfidf['precision']:.4f}, Recall={best_tfidf['recall']:.4f})\")\n",
        "else:\n",
        "    lines.append(\"No TF-IDF models available to pick best.\")\n",
        "\n",
        "lines.append(\"\")\n",
        "if lstm_best or cnn_best or mlp_best:\n",
        "    lines.append(\"Architecture comparison (best per family if available):\")\n",
        "    if lstm_best:\n",
        "        lines.append(f\"  - LSTM best  : {lstm_best.get('model','LSTM')}  (F1={float(lstm_best['f1']):.4f})\")\n",
        "    else:\n",
        "        lines.append(\"  - LSTM best  : N/A\")\n",
        "    if cnn_best:\n",
        "        lines.append(f\"  - CNN best   : {cnn_best.get('model','CNN')}   (F1={float(cnn_best['f1']):.4f})\")\n",
        "    else:\n",
        "        lines.append(\"  - CNN best   : N/A\")\n",
        "    if mlp_best:\n",
        "        lines.append(f\"  - MLP best   : {mlp_best.get('model','MLP')}   (F1={float(mlp_best['f1']):.4f})\")\n",
        "    else:\n",
        "        lines.append(\"  - MLP best   : N/A\")\n",
        "\n",
        "    # Is LSTM better than others?\n",
        "    # Compare best available F1s\n",
        "    best_family = None\n",
        "    family_scores = {}\n",
        "    if lstm_best:\n",
        "        family_scores['LSTM'] = float(lstm_best['f1'])\n",
        "    if cnn_best:\n",
        "        family_scores['CNN'] = float(cnn_best['f1'])\n",
        "    if mlp_best:\n",
        "        family_scores['MLP'] = float(mlp_best['f1'])\n",
        "    if family_scores:\n",
        "        best_family = max(family_scores, key=family_scores.get)\n",
        "        lines.append(f\"\\nConclusion: The family with highest best-F1 is {best_family} (score {family_scores[best_family]:.4f}).\")\n",
        "    else:\n",
        "        lines.append(\"\\nConclusion: Not enough DL models to compare families.\")\n",
        "else:\n",
        "    lines.append(\"No DL architecture results available for family-wise comparison.\")\n",
        "\n",
        "# Final practical notes\n",
        "lines.append(\"\")\n",
        "lines.append(\"Practical notes / next steps:\")\n",
        "lines.append(\" - If TF-IDF outperforms embeddings, tune embeddings (use pretrained GloVe, allow fine-tuning) or add class weighting/threshold tuning.\")\n",
        "lines.append(\" - If DL models overfit, reduce model size, add dropout, or get more data / augment.\")\n",
        "lines.append(\" - Use threshold sweep and class-weighting to optimize for recall/F1 on the disaster class if that's your priority.\")\n",
        "\n",
        "# Print lines\n",
        "report_text = \"\\n\".join(lines)\n",
        "print(report_text)\n",
        "\n",
        "# Save to file\n",
        "with open(\"brief_analysis.txt\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "print(\"\\nSaved brief analysis to brief_analysis.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfuvPoKHTOT8",
        "outputId": "be108de8-66d6-40ab-d766-56f2f61f3891"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: no TF-IDF classical models found in results to compare.\n",
            "BRIEF ANALYSIS - Disaster Tweets Experiment\n",
            "==========================================\n",
            "TF-IDF models found: 0, DL models found: 3\n",
            "\n",
            "Mean metrics:\n",
            "  - TF-IDF mean F1 : N/A\n",
            "  - DL mean F1     : 0.4178\n",
            "\n",
            "Not enough data to compare TF-IDF and DL mean F1.\n",
            "\n",
            "Best DL model by F1: Bidirectional LSTM  (F1=0.6347, Precision=0.7532, Recall=0.5485)\n",
            "No TF-IDF models available to pick best.\n",
            "\n",
            "Architecture comparison (best per family if available):\n",
            "  - LSTM best  : Bidirectional LSTM  (F1=0.6347)\n",
            "  - CNN best   : 1D-CNN   (F1=0.6185)\n",
            "  - MLP best   : MLP (avg embeddings)   (F1=0.0000)\n",
            "\n",
            "Conclusion: The family with highest best-F1 is LSTM (score 0.6347).\n",
            "\n",
            "Practical notes / next steps:\n",
            " - If TF-IDF outperforms embeddings, tune embeddings (use pretrained GloVe, allow fine-tuning) or add class weighting/threshold tuning.\n",
            " - If DL models overfit, reduce model size, add dropout, or get more data / augment.\n",
            " - Use threshold sweep and class-weighting to optimize for recall/F1 on the disaster class if that's your priority.\n",
            "\n",
            "Saved brief analysis to brief_analysis.txt\n"
          ]
        }
      ]
    }
  ]
}