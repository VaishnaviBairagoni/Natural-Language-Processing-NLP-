{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNyJj5hvX3Tu09LZERffrl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaishnaviBairagoni/Natural-Language-Processing-NLP-/blob/main/(NLP-T-11-9-2025).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbst5p-SUWkl",
        "outputId": "3c0754b0-9cae-4b30-e5e2-42b9e254a75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  Communal violence in Bhainsa, Telangana. \"Ston...   \n",
            "1  Telangana: Section 144 has been imposed in Bha...   \n",
            "2  Arsonist sets cars ablaze at dealership https:...   \n",
            "3  Arsonist sets cars ablaze at dealership https:...   \n",
            "4  \"Lord Jesus, your love brings freedom and pard...   \n",
            "\n",
            "                                               clean  \n",
            "0  communal violence bhainsa telangana stone pelt...  \n",
            "1  telangana section imposed bhainsa january clas...  \n",
            "2                 arsonist set car ablaze dealership  \n",
            "3                 arsonist set car ablaze dealership  \n",
            "4  lord jesus love brings freedom pardon fill hol...  \n"
          ]
        }
      ],
      "source": [
        "# Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download resources (only once)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# Initialize tools\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
        "\n",
        "    # 3. Remove numbers\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "    # 4. Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # 5. Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 6. Remove stopwords and lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    # 7. Join back into a single string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Example usage with your dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset (adjust path if needed)\n",
        "df = pd.read_csv(\"/content/tweets.csv\")\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"clean\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "print(df[[\"text\", \"clean\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction: TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and test\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    df[\"clean\"].values,\n",
        "    df[\"target\"].values,\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"target\"].values,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# TF-IDF Vectorizer with unigrams + bigrams\n",
        "tfidf_vect = TfidfVectorizer(\n",
        "    max_features=10000,      # keep top 10k features\n",
        "    ngram_range=(1, 2),      # unigrams + bigrams\n",
        "    min_df=2,                # ignore rare terms\n",
        "    norm=\"l2\",\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "# Fit on training data, transform train and test\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train_raw)\n",
        "X_test_tfidf = tfidf_vect.transform(X_test_raw)\n",
        "\n",
        "print(\"TF-IDF train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF test shape :\", X_test_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nArD1ImVv_u",
        "outputId": "7bf3df9e-90bb-415c-e083-b687e6177d2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF train shape: (9096, 10000)\n",
            "TF-IDF test shape : (2274, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Deep Learning Models: MLP, 1D-CNN, Bi-LSTM\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (Input, Embedding, GlobalAveragePooling1D, Dense, Dropout,\n",
        "                                     Conv1D, GlobalMaxPooling1D, SpatialDropout1D,\n",
        "                                     LSTM, Bidirectional)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "# Hyperparameters (tweak if needed)\n",
        "MAX_NUM_WORDS = 20000\n",
        "MAX_SEQUENCE_LENGTH = 60   # tweets are short\n",
        "EMBEDDING_DIM = 100\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 6\n",
        "\n",
        "#Tokenize + Pad\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_raw)   # X_train_raw should be list/array of cleaned strings\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_raw)\n",
        "X_test_seq  = tokenizer.texts_to_sequences(X_test_raw)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
        "X_test_pad  = pad_sequences(X_test_seq,  maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "vocab_size = min(MAX_NUM_WORDS, len(tokenizer.word_index) + 1)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "# Save tokenizer for later use\n",
        "joblib.dump(tokenizer, \"tokenizer.joblib\")\n",
        "\n",
        "# Early stopping\n",
        "es = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True, verbose=1)\n",
        "\n",
        "results = []\n",
        "\n",
        "def eval_and_store(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall   : {rec:.4f}\")\n",
        "    print(f\"F1-score : {f1:.4f}\")\n",
        "    print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
        "    results.append({\"model\": name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1})\n",
        "\n",
        "# Model 1: MLP on averaged embeddings\n",
        "print(\"\\nBuilding / training: MLP (avg embeddings)\")\n",
        "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
        "emb = Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(inputs)\n",
        "x = GlobalAveragePooling1D()(emb)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "mlp_model = Model(inputs, outputs)\n",
        "mlp_model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "mlp_model.summary()\n",
        "mlp_model.fit(X_train_pad, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
        "\n",
        "y_prob = mlp_model.predict(X_test_pad, verbose=0).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "eval_and_store(\"MLP (avg embeddings)\", y_test, y_pred)\n",
        "\n",
        "# Save model\n",
        "mlp_model.save(\"mlp_avg_embeddings.h5\")\n",
        "\n",
        "# Model 2: 1D-CNN\n",
        "print(\"\\nBuilding / training: 1D-CNN\")\n",
        "cnn = Sequential()\n",
        "cnn.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "cnn.add(Conv1D(128, kernel_size=5, activation=\"relu\"))\n",
        "cnn.add(GlobalMaxPooling1D())\n",
        "cnn.add(Dense(64, activation=\"relu\"))\n",
        "cnn.add(Dropout(0.3))\n",
        "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
        "cnn.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "cnn.summary()\n",
        "cnn.fit(X_train_pad, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
        "\n",
        "y_prob = cnn.predict(X_test_pad, verbose=0).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "eval_and_store(\"1D-CNN\", y_test, y_pred)\n",
        "\n",
        "# Save model\n",
        "cnn.save(\"cnn_text.h5\")\n",
        "\n",
        "# Model 3: Bidirectional LSTM\n",
        "print(\"\\nBuilding / training: Bidirectional LSTM\")\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "lstm_model.add(SpatialDropout1D(0.2))\n",
        "lstm_model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
        "lstm_model.add(Dense(64, activation=\"relu\"))\n",
        "lstm_model.add(Dropout(0.3))\n",
        "lstm_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "lstm_model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "lstm_model.summary()\n",
        "lstm_model.fit(X_train_pad, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es], verbose=1)\n",
        "\n",
        "y_prob = lstm_model.predict(X_test_pad, verbose=0).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "eval_and_store(\"Bidirectional LSTM\", y_test, y_pred)\n",
        "\n",
        "# Save model\n",
        "lstm_model.save(\"bilstm_text.h5\")\n",
        "\n",
        "# Save results\n",
        "res_df = pd.DataFrame(results).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
        "res_df.to_csv(\"dl_results.csv\", index=False)\n",
        "print(\"\\nSaved dl_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d-zlyIVkWiNm",
        "outputId": "c94aa7e4-96a6-4c13-a967-0e36de6a6b29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 19399\n",
            "\n",
            "Building / training: MLP (avg embeddings)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,939,900\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,939,900</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,946,429\u001b[0m (7.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,946,429</span> (7.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,946,429\u001b[0m (7.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,946,429</span> (7.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.7644 - loss: 0.5270 - val_accuracy: 0.7912 - val_loss: 0.5078\n",
            "Epoch 2/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.8125 - loss: 0.4813 - val_accuracy: 0.7912 - val_loss: 0.5048\n",
            "Epoch 3/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8125 - loss: 0.4749 - val_accuracy: 0.7912 - val_loss: 0.4988\n",
            "Epoch 4/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8125 - loss: 0.4691 - val_accuracy: 0.7912 - val_loss: 0.4842\n",
            "Epoch 5/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.4478 - val_accuracy: 0.7912 - val_loss: 0.4494\n",
            "Epoch 6/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8148 - loss: 0.4006 - val_accuracy: 0.7956 - val_loss: 0.4259\n",
            "Restoring model weights from the end of the best epoch: 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Model: MLP (avg embeddings)\n",
            "Accuracy : 0.8162\n",
            "Precision: 1.0000\n",
            "Recall   : 0.0118\n",
            "F1-score : 0.0234\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8158    1.0000    0.8985      1851\n",
            "           1     1.0000    0.0118    0.0234       423\n",
            "\n",
            "    accuracy                         0.8162      2274\n",
            "   macro avg     0.9079    0.5059    0.4610      2274\n",
            "weighted avg     0.8500    0.8162    0.7357      2274\n",
            "\n",
            "\n",
            "Building / training: 1D-CNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.8108 - loss: 0.5183 - val_accuracy: 0.7912 - val_loss: 0.4519\n",
            "Epoch 2/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.8448 - loss: 0.3361 - val_accuracy: 0.8923 - val_loss: 0.3210\n",
            "Epoch 3/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.9585 - loss: 0.1185 - val_accuracy: 0.8758 - val_loss: 0.4103\n",
            "Epoch 4/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - accuracy: 0.9880 - loss: 0.0416 - val_accuracy: 0.8857 - val_loss: 0.5223\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Model: 1D-CNN\n",
            "Accuracy : 0.8786\n",
            "Precision: 0.7094\n",
            "Recall   : 0.5887\n",
            "F1-score : 0.6434\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9095    0.9449    0.9269      1851\n",
            "           1     0.7094    0.5887    0.6434       423\n",
            "\n",
            "    accuracy                         0.8786      2274\n",
            "   macro avg     0.8095    0.7668    0.7851      2274\n",
            "weighted avg     0.8723    0.8786    0.8741      2274\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building / training: Bidirectional LSTM\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.8103 - loss: 0.5168 - val_accuracy: 0.8308 - val_loss: 0.3821\n",
            "Epoch 2/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 249ms/step - accuracy: 0.8895 - loss: 0.2826 - val_accuracy: 0.8901 - val_loss: 0.3098\n",
            "Epoch 3/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 264ms/step - accuracy: 0.9493 - loss: 0.1372 - val_accuracy: 0.8879 - val_loss: 0.3717\n",
            "Epoch 4/6\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 246ms/step - accuracy: 0.9741 - loss: 0.0737 - val_accuracy: 0.8714 - val_loss: 0.4709\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Model: Bidirectional LSTM\n",
            "Accuracy : 0.8795\n",
            "Precision: 0.7159\n",
            "Recall   : 0.5839\n",
            "F1-score : 0.6432\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9088    0.9471    0.9275      1851\n",
            "           1     0.7159    0.5839    0.6432       423\n",
            "\n",
            "    accuracy                         0.8795      2274\n",
            "   macro avg     0.8124    0.7655    0.7854      2274\n",
            "weighted avg     0.8729    0.8795    0.8746      2274\n",
            "\n",
            "\n",
            "Saved dl_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Evaluation Section ----------------\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "all_results = []\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    \"\"\"Compute metrics, print report, and store in all_results list.\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall   : {rec:.4f}\")\n",
        "    print(f\"F1-score : {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "    all_results.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "\n",
        "# -------- Logistic Regression (TF-IDF) --------\n",
        "if \"lr\" in globals():\n",
        "    y_pred_lr = lr.predict(X_test_tfidf)\n",
        "    evaluate_model(\"Logistic Regression (TF-IDF)\", y_test, y_pred_lr)\n",
        "\n",
        "# -------- SVM (TF-IDF) --------\n",
        "if \"svc\" in globals():\n",
        "    y_pred_svc = svc.predict(X_test_tfidf)\n",
        "    evaluate_model(\"SVM (TF-IDF)\", y_test, y_pred_svc)\n",
        "\n",
        "# -------- MLP --------\n",
        "if \"mlp_model\" in globals():\n",
        "    y_pred_mlp = (mlp_model.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "    evaluate_model(\"MLP (avg embeddings)\", y_test, y_pred_mlp)\n",
        "\n",
        "# -------- 1D-CNN --------\n",
        "if \"cnn\" in globals():\n",
        "    y_pred_cnn = (cnn.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "    evaluate_model(\"1D-CNN\", y_test, y_pred_cnn)\n",
        "\n",
        "# -------- Bi-LSTM --------\n",
        "if \"lstm_model\" in globals():\n",
        "    y_pred_lstm = (lstm_model.predict(X_test_pad, verbose=0).ravel() >= 0.5).astype(int)\n",
        "    evaluate_model(\"Bi-LSTM\", y_test, y_pred_lstm)\n",
        "\n",
        "# -------- Save comparison summary --------\n",
        "results_df = pd.DataFrame(all_results).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
        "results_df.to_csv(\"evaluation_summary.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved evaluation_summary.csv with all model metrics\")\n",
        "print(\"\\nFinal Results Table:\\n\", results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK9W5UBkXQze",
        "outputId": "7238bd5d-6a8d-455b-b08c-5138407ec4be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Model: MLP (avg embeddings)\n",
            "Accuracy : 0.8162\n",
            "Precision: 1.0000\n",
            "Recall   : 0.0118\n",
            "F1-score : 0.0234\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8158    1.0000    0.8985      1851\n",
            "           1     1.0000    0.0118    0.0234       423\n",
            "\n",
            "    accuracy                         0.8162      2274\n",
            "   macro avg     0.9079    0.5059    0.4610      2274\n",
            "weighted avg     0.8500    0.8162    0.7357      2274\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: 1D-CNN\n",
            "Accuracy : 0.8786\n",
            "Precision: 0.7094\n",
            "Recall   : 0.5887\n",
            "F1-score : 0.6434\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9095    0.9449    0.9269      1851\n",
            "           1     0.7094    0.5887    0.6434       423\n",
            "\n",
            "    accuracy                         0.8786      2274\n",
            "   macro avg     0.8095    0.7668    0.7851      2274\n",
            "weighted avg     0.8723    0.8786    0.8741      2274\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: Bi-LSTM\n",
            "Accuracy : 0.8795\n",
            "Precision: 0.7159\n",
            "Recall   : 0.5839\n",
            "F1-score : 0.6432\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9088    0.9471    0.9275      1851\n",
            "           1     0.7159    0.5839    0.6432       423\n",
            "\n",
            "    accuracy                         0.8795      2274\n",
            "   macro avg     0.8124    0.7655    0.7854      2274\n",
            "weighted avg     0.8729    0.8795    0.8746      2274\n",
            "\n",
            "\n",
            "Saved evaluation_summary.csv with all model metrics\n",
            "\n",
            "Final Results Table:\n",
            "                   model  accuracy  precision    recall        f1\n",
            "0                1D-CNN  0.878628   0.709402  0.588652  0.643411\n",
            "1               Bi-LSTM  0.879507   0.715942  0.583924  0.643229\n",
            "2  MLP (avg embeddings)  0.816183   1.000000  0.011820  0.023364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Brief Analysis ----------------\n",
        "import pandas as pd\n",
        "\n",
        "# Load results\n",
        "results_df = pd.read_csv(\"evaluation_summary.csv\")\n",
        "\n",
        "print(\"\\n=== Brief Analysis ===\")\n",
        "print(results_df)\n",
        "\n",
        "# Find best model by F1\n",
        "best_model = results_df.loc[results_df[\"f1\"].idxmax()]\n",
        "print(f\"\\nBest model overall: {best_model['model']} with F1 = {best_model['f1']:.4f}\")\n",
        "\n",
        "# Separate classical ML and deep learning\n",
        "ml_models = [\"Logistic Regression (TF-IDF)\", \"SVM (TF-IDF)\"]\n",
        "dl_models = [m for m in results_df[\"model\"].tolist() if m not in ml_models]\n",
        "\n",
        "ml_f1 = results_df[results_df[\"model\"].isin(ml_models)][\"f1\"].mean()\n",
        "dl_f1 = results_df[results_df[\"model\"].isin(dl_models)][\"f1\"].mean()\n",
        "\n",
        "print(f\"\\nAverage F1 - Classical ML (TF-IDF): {ml_f1:.4f}\")\n",
        "print(f\"Average F1 - Deep Learning (embeddings): {dl_f1:.4f}\")\n",
        "\n",
        "if dl_f1 > ml_f1:\n",
        "    print(\"=> Deep learning outperformed classical ML overall.\")\n",
        "else:\n",
        "    print(\"=> Classical ML held its ground against deep learning.\")\n",
        "\n",
        "# Compare architectures inside DL\n",
        "if \"Bi-LSTM\" in results_df[\"model\"].values:\n",
        "    bilstm_f1 = results_df.loc[results_df[\"model\"] == \"Bi-LSTM\", \"f1\"].values[0]\n",
        "    cnn_f1 = results_df.loc[results_df[\"model\"] == \"1D-CNN\", \"f1\"].values[0]\n",
        "    mlp_f1 = results_df.loc[results_df[\"model\"] == \"MLP (avg embeddings)\", \"f1\"].values[0]\n",
        "\n",
        "    print(f\"\\nBi-LSTM F1: {bilstm_f1:.4f}\")\n",
        "    print(f\"1D-CNN F1 : {cnn_f1:.4f}\")\n",
        "    print(f\"MLP F1    : {mlp_f1:.4f}\")\n",
        "\n",
        "    if bilstm_f1 > max(cnn_f1, mlp_f1):\n",
        "        print(\"=> Bi-LSTM captured sequential patterns better than CNN/MLP.\")\n",
        "    else:\n",
        "        print(\"=> Bi-LSTM did not clearly outperform CNN/MLP.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHtVfSWqXql9",
        "outputId": "dbf57f0c-3105-4951-996e-36aa1a06b983"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Brief Analysis ===\n",
            "                  model  accuracy  precision    recall        f1\n",
            "0                1D-CNN  0.878628   0.709402  0.588652  0.643411\n",
            "1               Bi-LSTM  0.879507   0.715942  0.583924  0.643229\n",
            "2  MLP (avg embeddings)  0.816183   1.000000  0.011820  0.023364\n",
            "\n",
            "Best model overall: 1D-CNN with F1 = 0.6434\n",
            "\n",
            "Average F1 - Classical ML (TF-IDF): nan\n",
            "Average F1 - Deep Learning (embeddings): 0.4367\n",
            "=> Classical ML held its ground against deep learning.\n",
            "\n",
            "Bi-LSTM F1: 0.6432\n",
            "1D-CNN F1 : 0.6434\n",
            "MLP F1    : 0.0234\n",
            "=> Bi-LSTM did not clearly outperform CNN/MLP.\n"
          ]
        }
      ]
    }
  ]
}